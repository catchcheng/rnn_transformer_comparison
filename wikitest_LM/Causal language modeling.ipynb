{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "010f2995-7899-43bf-b0a9-3a44083d8cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install datasets transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1c5bfc-cc43-49ec-af16-37f5f6134297",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Causal language modeling\n",
    "the model has to predict the next token in the sentence (so the labels are the same as the inputs shifted to the right). To make sure the model does not cheat, it gets an attention mask that will prevent it to access the tokens after token i when trying to predict the token i+1 in the sentence.\n",
    "## Masked language modeling\n",
    "the model has to predict some tokens that are masked in the input. It still has access to the whole sentence, so it can use the tokens before and after the tokens masked to predict their value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff7cf26d-b55b-4dad-a6c9-c76f01fe2a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "datasets = load_dataset('wikitext', 'wikitext-2-raw-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7ea9fbc-505d-44d8-8f95-a2ed506e5469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' The game \\'s battle system , the BliTZ system , is carried over directly from Valkyira Chronicles . During missions , players select each unit using a top @-@ down perspective of the battlefield map : once a character is selected , the player moves the character around the battlefield in third @-@ person . A character can only act once per @-@ turn , but characters can be granted multiple turns at the expense of other characters \\' turns . Each character has a field and distance of movement limited by their Action Gauge . Up to nine characters can be assigned to a single mission . During gameplay , characters will call out if something happens to them , such as their health points ( HP ) getting low or being knocked out by enemy attacks . Each character has specific \" Potentials \" , skills unique to each character . They are divided into \" Personal Potential \" , which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character , and \" Battle Potentials \" , which are grown throughout the game and always grant boons to a character . To learn Battle Potentials , each character has a unique \" Masters Table \" , a grid @-@ based skill table that can be used to acquire and link different skills . Characters also have Special Abilities that grant them temporary boosts on the battlefield : Kurt can activate \" Direct Command \" and move around the battlefield without depleting his Action Point gauge , the character Reila can shift into her \" Valkyria Form \" and become invincible , while Imca can target multiple enemy units with her heavy weapon . \\n'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3cfc721-7541-4bcb-a50b-037347a4ce00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The earliest known written version of the Laws of Cricket , dating from 1744 , does not include an lbw rule . At the time , batsmen in English cricket used curved bats , which made it unlikely that they would be able to stand directly in front of the wickets . However , a clause in the 1744 laws gave umpires the power to take action if the batsman was \" standing unfair to strike \" . Cricket bats were modified to become straighter over the following years , allowing batsmen to stand closer to the wickets . Subsequently , some players deliberately began to obstruct the ball from hitting the wickets . Such tactics were criticised by writers and a revision of the laws in 1774 ruled that the batsman was out if he deliberately stopped the ball from hitting the wicket with his leg . However , critics noted that the umpires were left the difficult task of interpreting the intentions of batsmen . The 1788 version of the laws no longer required the umpires to take account of the batsman 's intent ; now a batsman was lbw if he stopped a ball that \" pitch [ ed ] straight \" . Further clarification of the law came in 1823 , when a condition was added that \" the ball must be delivered in a straight line to the wicket \" . The ambiguity of the wording was highlighted when two prominent umpires disagreed over whether the ball had to travel in a straight line from the bowler to the wicket , or between the wickets at either end of the pitch . In 1839 the MCC , by then responsible for drafting the Laws of Cricket , endorsed the latter interpretation and ruled the batsman out lbw if the ball pitched in between the wickets and would have hit the stumps . \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In the two @-@ part finale to series two , \" Counterfeit \" ( 1994 ) , James Horton ( Peter Hudson ) , a renegade Watcher who believes all Immortals must be eliminated , uses killer Lisa Halle ( Meilani Paul ) to try and kill MacLeod . Lisa undergoes plastic surgery to resemble Tessa and therefore is played by Vandernoot from that point on . MacLeod meets Lisa just after he admitted to himself how much he missed Tessa , and he is stunned by her resemblance with Tessa . Despite knowing that Tessa is dead and cannot return , he eagerly pursues a relationship with Lisa . He eventually admits the truth when he discovers a scar on Lisa 's jaw . Horton kills Lisa on Tessa 's grave before being himself killed by MacLeod . \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After reigning for barely one month , Zhang Bangchang was persuaded by the Song to step down as emperor of the Great Chu and to recognize the legitimacy of the Song imperial line . Li Gang pressured Gaozong to execute Zhang for betraying the Song . The emperor relented and Zhang was coerced into suicide . The killing of Zhang showed that the Song was willing to provoke the Jin , and that the Jin had yet to solidify their control over the newly conquered territories . The submission and abolition of Chu meant that Kaifeng was now back under Song control . Zong Ze ( 宗澤 ; 1059 – 1128 ) , the Song general responsible for fortifying Kaifeng , entreated Gaozong to move the court back to the city , but Gaozong refused and retreated south . The southward move marked the end of the Northern Song and the beginning of the Southern Song era of Chinese history . \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>= = = Setting = = = \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>= = Playing style = = \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Piggott claimed that Wheeler 's appointment as Director @-@ General of the Archaeological Survey of India represented \" the most remarkable archaeological achievement of his career , an enormous challenge accepted and surmounted in the autocratic and authoritarian terms within which he could best deploy his powers as administrator and excavator . No other archaeologist of the time , it seems fair to remark , could have come near to attaining his command of incisive strategy and often ruthless tactics which won him the bewildered admiration and touching devotion of his Indian staff . \" The Indian archaeologist Dilip K. Chakrabarti later stated that Wheeler 's accomplishments while in India were \" considerable \" , particularly given the socio @-@ political turmoil of independence and partition . Chakrabarti stated that Wheeler had contributed to South Asian archaeology in various ways : by establishing a \" total view \" of the region 's development from the Palaeolithic onward , by introducing new archaeological techniques and methodologies to the subcontinent , and by encouraging Indian universities to begin archaeological research . Ultimately , Chakrabarti was of the opinion that Wheeler had \" prepared the archaeology of the subcontinent for its transition to modernity in the post @-@ Partition period . \" Similarly , Peter Johansen praised Wheeler for systematising and professionalising Indian archaeology and for \" instituting a clearly defined body of techniques and methods for field and laboratory work and training . \" \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import ClassLabel\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))\n",
    "    \n",
    "show_random_elements(datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57a49839-c43e-402f-b498-5df3d1c7706a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# model_checkpoint = \"distilgpt2\"\n",
    "# model_checkpoint = \"EleutherAI/pythia-70m-deduped\"\n",
    "# model_checkpoint = \"EleutherAI/pythia-160m\"\n",
    "model_checkpoint = \"RWKV/rwkv-4-169m-pile\"\n",
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f8624c9-e6a3-4ed8-b80d-5f0b4f35309b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [426, 657, 1278, 90, 5182, 28289, 868, 6490, 426, 2490],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"])\n",
    "    \n",
    "tokenized_datasets = datasets.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"])\n",
    "tokenized_datasets[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84ba339f-dc95-4d04-ae87-ee3bef66ecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# block_size = tokenizer.model_max_length\n",
    "block_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ab43a43-05b3-4714-88a9-bf54bb7d1fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d45d782-21cb-4c17-ac7d-c95157cc2978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 23:53:17.342662: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-11 23:53:17.343977: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-11 23:53:17.359797: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-11 23:53:17.359812: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-11 23:53:17.359825: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-11 23:53:17.363781: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-11 23:53:17.825874: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' time gameplay as its predecessors, the story runs parallel to the first game and follows the \" Nameless \", a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \". \\n The game began development in 2010, carrying over a large portion of the work done on Valkyria Chronicles II. While it retained the standard features of the series, it also underwent multiple adjustments, such as making the game more forgiving for series newcomers. Character designer Raita Honjou and composer Hitoshi Sakimoto both'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets[\"train\"][1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e50d3c1-86d6-49ed-a4ba-502ef32600cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cheng-ubuntu/anaconda3/envs/6758hmk4/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(model_checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f798f068-bbbe-4714-a68c-18d7eb1049fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 229,376 || all params: 169,571,840 || trainable%: 0.13526774256857743\n"
     ]
    }
   ],
   "source": [
    "# Add peft\n",
    "\n",
    "from peft import get_peft_config, get_peft_model, PrefixTuningConfig, TaskType, PeftType, get_peft_model_state_dict, set_peft_model_state_dict, PromptEncoderConfig\n",
    "\n",
    "# ## Prefix-tuning\n",
    "# peft_config = PrefixTuningConfig(task_type=TaskType.CAUSAL_LM, num_virtual_tokens=30, num_attention_heads=12)\n",
    "\n",
    "## P-tuning\n",
    "peft_type = PeftType.P_TUNING\n",
    "# peft_config = PromptEncoderConfig(task_type=\"SEQ_CLS\", num_virtual_tokens=20, encoder_hidden_size=128)\n",
    "peft_config = PromptEncoderConfig(task_type=\"CAUSAL_LM\", num_virtual_tokens=20, encoder_hidden_size=128, num_attention_heads=12)\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f47e908-3412-4f9c-8cd6-75f2d5579b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1f5800b-f57b-4f66-83cb-5ce5e480c0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "comet_ml is installed but `COMET_API_KEY` is not set.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "training_args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-wikitext2\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28dc0a0e-7a50-425f-8590-c7e3eb71ff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"validation\"],\n",
    ")\n",
    "\n",
    "# # Zero shot evaluation\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8e0a684-64bc-471d-8d2b-cbc82447023a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='244' max='244' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [244/244 00:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myimei-yang\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/cheng-ubuntu/Documents/ift6759/wandb/run-20240411_235358-lwd8fa9c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yimei-yang/huggingface/runs/lwd8fa9c' target=\"_blank\">fresh-aardvark-23</a></strong> to <a href='https://wandb.ai/yimei-yang/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yimei-yang/huggingface' target=\"_blank\">https://wandb.ai/yimei-yang/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yimei-yang/huggingface/runs/lwd8fa9c' target=\"_blank\">https://wandb.ai/yimei-yang/huggingface/runs/lwd8fa9c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 60.05\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55d78f5-d8dc-4783-affb-9bbfd7e742bc",
   "metadata": {},
   "source": [
    "Perplexity: 45.93 for pythia-70m-deduped\n",
    "\n",
    "Perplexity: 34.95 for pythia-160m-deduped, with pre-fix tuning: 1105.27, with p-tuning: 39.32\n",
    "\n",
    "Perplexity: 26.12 for RWKV/rwkv-4-169m-pile, with p-tuning: 35.49\n",
    "\n",
    "Perplexity: 61.54 for pythia-160m zero shot evaluation, with pre-fix tuning: 1516.04, with p-tuning: 87.91\n",
    "\n",
    "Perplexity: 51.08 for RWKV/rwkv-4-169m-pile zero shot evaluation, with p-tuning: 60.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624439c1-6e8b-4d96-8a6a-298af0b7b257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "6758hmk4",
   "language": "python",
   "name": "6758hmk4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
