{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "010f2995-7899-43bf-b0a9-3a44083d8cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install datasets transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1c5bfc-cc43-49ec-af16-37f5f6134297",
   "metadata": {},
   "source": [
    "## Causal language modeling\n",
    "the model has to predict the next token in the sentence (so the labels are the same as the inputs shifted to the right). To make sure the model does not cheat, it gets an attention mask that will prevent it to access the tokens after token i when trying to predict the token i+1 in the sentence.\n",
    "## Masked language modeling\n",
    "the model has to predict some tokens that are masked in the input. It still has access to the whole sentence, so it can use the tokens before and after the tokens masked to predict their value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff7cf26d-b55b-4dad-a6c9-c76f01fe2a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "datasets = load_dataset('wikitext', 'wikitext-2-raw-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7ea9fbc-505d-44d8-8f95-a2ed506e5469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' The game \\'s battle system , the BliTZ system , is carried over directly from Valkyira Chronicles . During missions , players select each unit using a top @-@ down perspective of the battlefield map : once a character is selected , the player moves the character around the battlefield in third @-@ person . A character can only act once per @-@ turn , but characters can be granted multiple turns at the expense of other characters \\' turns . Each character has a field and distance of movement limited by their Action Gauge . Up to nine characters can be assigned to a single mission . During gameplay , characters will call out if something happens to them , such as their health points ( HP ) getting low or being knocked out by enemy attacks . Each character has specific \" Potentials \" , skills unique to each character . They are divided into \" Personal Potential \" , which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character , and \" Battle Potentials \" , which are grown throughout the game and always grant boons to a character . To learn Battle Potentials , each character has a unique \" Masters Table \" , a grid @-@ based skill table that can be used to acquire and link different skills . Characters also have Special Abilities that grant them temporary boosts on the battlefield : Kurt can activate \" Direct Command \" and move around the battlefield without depleting his Action Point gauge , the character Reila can shift into her \" Valkyria Form \" and become invincible , while Imca can target multiple enemy units with her heavy weapon . \\n'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3cfc721-7541-4bcb-a50b-037347a4ce00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Titanoceratops - ( New Mexico , USA ) \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As of 1984 , the mean annual precipitation for the Loyalsock Creek watershed ( which Plunketts Creek is part of ) was 42 to 48 inches ( 1067 to 1219 mm ) . Pennsylvania receives the greatest amount of acid rain of any state in the United States . Because Plunketts Creek is in a sandstone and shale mountain region , it has a relatively low capacity to neutralize added acid . This makes it especially vulnerable to increased acidification from acid rain , which poses a threat to the long term health of the plants and animals in the creek . The total alkalinity ( TA ) is a measure of the capacity of water to neutralize acid , with a larger TA corresponding to a greater capacity . In 2007 , the TA of two subtributaries was known : Engle Run , a 4 @.@ 9 @-@ mile ( 7 @.@ 9 km ) tributary of King Run , had a TA of 5 , and the Noon Branch , a 1 @.@ 9 @-@ mile ( 3 @.@ 1 km ) tributary of Wolf Run , had a TA of 9 . \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The episode was broadcast online by Netflix on February 1 , 2013 as part of the simultaneous release of all 13 episodes of season 1 of the series . The debut date was a weekend when there was little competition on television other than Super Bowl XLVII and a new episode of Downton Abbey on PBS . Netflix broadcast \" Chapter 1 \" and \" Chapter 2 \" to critics several days in advance of the release . \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 1975 tour with the Revue provided the backdrop to Dylan 's nearly four @-@ hour film Renaldo and Clara , a sprawling narrative mixed with concert footage and reminiscences . Released in 1978 , the movie received poor , sometimes scathing , reviews . Later in that year , a two @-@ hour edit , dominated by the concert performances , was more widely released . \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>= = Service history = = \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Editor Christopher Gay spoke about the episode in August 2012 : \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>On 26 July , Federer announced that he would miss the 2016 Summer Olympics and the remainder of the 2016 season to fully recover from his knee injury . \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\" Mothers of the Disappeared \" was favourably received by critics . Steve Morse of The Boston Globe called the song \" powerful \" and described the backing vocals as tender and choirlike . Don McLeese of the Chicago Sun @-@ Times described it as a \" hymn to human rights \" . Adrian Thrills of NME called it \" a simple , plaintive lament of stunning beauty and sadness \" . Nicholas Jennings of Maclean 's felt that it was The Joshua Tree 's \" most topical song \" . Music journalist Andrew Mueller felt the track was a \" wilfully downbeat finale \" . In Rolling Stone , Steve Pond said \" ' Mothers of the Disappeared ' is built around desolate images of loss , but the setting is soothing and restorative â€” music of great sadness but also of unutterable compassion , acceptance and calm . \" Lennox Samuels of The Dallas Morning News stated that there was \" an ineffable sadness in Bono 's vocals and images where ' Night hangs like a prisoner / Stretched over black and blue ' \" , calling it \" a moving tribute \" to people around the world who had lost loved ones to warfare and conflict . He added \" [ w ] hat 's remarkable about the song is that despite the intrinsic pain , it remains eerily cleansing . Even in the midst of decay and excess and horror , Bono can find hope and absolution . \" In 2006 Bono described it as \" a beautiful end to the album \" , saying , \" That song means as much to me as any of the songs on that album , it 's right up there for me , \" and noting that it is a song \" I 'm very proud of to this day . \" \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import ClassLabel\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))\n",
    "    \n",
    "show_random_elements(datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57a49839-c43e-402f-b498-5df3d1c7706a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# model_checkpoint = \"distilgpt2\"\n",
    "# model_checkpoint = \"EleutherAI/pythia-70m-deduped\"\n",
    "# model_checkpoint = \"EleutherAI/pythia-160m\"\n",
    "model_checkpoint = \"RWKV/rwkv-4-169m-pile\"\n",
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f8624c9-e6a3-4ed8-b80d-5f0b4f35309b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [426, 657, 1278, 90, 5182, 28289, 868, 6490, 426, 2490],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"])\n",
    "    \n",
    "tokenized_datasets = datasets.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"])\n",
    "tokenized_datasets[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84ba339f-dc95-4d04-ae87-ee3bef66ecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# block_size = tokenizer.model_max_length\n",
    "block_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ab43a43-05b3-4714-88a9-bf54bb7d1fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d45d782-21cb-4c17-ac7d-c95157cc2978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-28 17:33:26.423494: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-28 17:33:26.424841: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-28 17:33:26.440724: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-28 17:33:26.440739: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-28 17:33:26.440752: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-28 17:33:26.444634: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-28 17:33:26.899567: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' time gameplay as its predecessors, the story runs parallel to the first game and follows the \" Nameless \", a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \". \\n The game began development in 2010, carrying over a large portion of the work done on Valkyria Chronicles II. While it retained the standard features of the series, it also underwent multiple adjustments, such as making the game more forgiving for series newcomers. Character designer Raita Honjou and composer Hitoshi Sakimoto both'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets[\"train\"][1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e50d3c1-86d6-49ed-a4ba-502ef32600cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cheng-ubuntu/anaconda3/envs/6758hmk4/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1f5800b-f57b-4f66-83cb-5ce5e480c0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "comet_ml is installed but `COMET_API_KEY` is not set.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "training_args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-wikitext2\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28dc0a0e-7a50-425f-8590-c7e3eb71ff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"validation\"],\n",
    ")\n",
    "\n",
    "# Zero shot evaluation\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8e0a684-64bc-471d-8d2b-cbc82447023a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='244' max='244' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [244/244 00:32]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myimei-yang\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/cheng-ubuntu/Documents/ift6759/wandb/run-20240328_173402-098sofzu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yimei-yang/huggingface/runs/098sofzu' target=\"_blank\">fluent-jazz-13</a></strong> to <a href='https://wandb.ai/yimei-yang/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yimei-yang/huggingface' target=\"_blank\">https://wandb.ai/yimei-yang/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yimei-yang/huggingface/runs/098sofzu' target=\"_blank\">https://wandb.ai/yimei-yang/huggingface/runs/098sofzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 51.08\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55d78f5-d8dc-4783-affb-9bbfd7e742bc",
   "metadata": {},
   "source": [
    "Perplexity: 45.93 for pythia-70m-deduped\n",
    "\n",
    "Perplexity: 34.95 for pythia-160m-deduped\n",
    "\n",
    "Perplexity: 26.12 for RWKV/rwkv-4-169m-pile\n",
    "\n",
    "Perplexity: 61.54 for pythia-160m zero shot evaluation\n",
    "\n",
    "Perplexity: 51.08 for RWKV/rwkv-4-169m-pile zero shot evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624439c1-6e8b-4d96-8a6a-298af0b7b257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "6758hmk4",
   "language": "python",
   "name": "6758hmk4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
