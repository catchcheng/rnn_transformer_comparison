{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1a1c196-3dd4-4d98-8c85-c996c1f40c88",
   "metadata": {},
   "source": [
    "# RWKV\n",
    "## causal model (7B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eacece54-d1b6-4ba7-acc4-f44c84794dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a1676e58f8494a8ad601f93b22da76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/510 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e95d6d89ec64f5b8b87f44ff7161e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin.index.json:   0%|          | 0.00/46.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88ba3ec873848a0979355e0a8c817db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d85d51a0f14049891bd9e1211eee20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00017.bin:   0%|          | 0.00/1.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db4dba31b9774da992f99159d3217294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00017.bin:   0%|          | 0.00/1.75G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b76cd7886a24b42aa27a86e69a4e263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00003-of-00017.bin:   0%|          | 0.00/1.75G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.huggingface.co/repos/1d/b4/1db41ee157433d618d43fe2d3dc71dbbd3de5fc7193475e70ae63214aa67df68/7196a847c59aa38b0a33616ec757e2815aa459f262fbfac57f066108bab96531?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27pytorch_model-00003-of-00017.bin%3B+filename%3D%22pytorch_model-00003-of-00017.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1709944159&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTk0NDE1OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy8xZC9iNC8xZGI0MWVlMTU3NDMzZDYxOGQ0M2ZlMmQzZGM3MWRiYmQzZGU1ZmM3MTkzNDc1ZTcwYWU2MzIxNGFhNjdkZjY4LzcxOTZhODQ3YzU5YWEzOGIwYTMzNjE2ZWM3NTdlMjgxNWFhNDU5ZjI2MmZiZmFjNTdmMDY2MTA4YmFiOTY1MzE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=jr7iJc72yurWiCM0lZE22wUYRHq4I6kS67sgQtCOwb9s8xEykDyaUgjbeBfmtvwiDoLJ5TLsPXoxDZEhCTnFW4FI0ZQpxDW4aO7428M7oZRcJB5QQ1HRwsxN-%7E84JpcJKHyPCCVPTKuW2Kqq%7ENv6hx0lsCAuYyQpy0nybdtgHh4pyfmrAxWNI0rOyeMYS7n5ba-ZhgTYGqH04Ugc3TBEEvcEVV1dGyVnsUTeX4Od2Y3I3XgZJKLcw33yWaks8HiijcAta4N-JDoyud8XwxtNvO1eFDBAmbNnH643HMZ2r-DJ3i5qXf6ZCyO8QkRKGbKajuH09IS9oQ4Itl39ZDp6dg__&Key-Pair-Id=KVTP0A1DKRTAX: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c458744b6f4ba0ab121c2e2633cdfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00003-of-00017.bin:  35%|###5      | 619M/1.75G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ddb8782141434d95d60f3cc4ae8ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00004-of-00017.bin:   0%|          | 0.00/1.75G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7436a458874207bd9f6e7b771c5321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00005-of-00017.bin:   0%|          | 0.00/1.75G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.huggingface.co/repos/1d/b4/1db41ee157433d618d43fe2d3dc71dbbd3de5fc7193475e70ae63214aa67df68/51100d89f4d2fac8ece9209dbee3680d9f1161f671a6ccc03ed9e6c2bfc90907?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27pytorch_model-00005-of-00017.bin%3B+filename%3D%22pytorch_model-00005-of-00017.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1709944922&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTk0NDkyMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy8xZC9iNC8xZGI0MWVlMTU3NDMzZDYxOGQ0M2ZlMmQzZGM3MWRiYmQzZGU1ZmM3MTkzNDc1ZTcwYWU2MzIxNGFhNjdkZjY4LzUxMTAwZDg5ZjRkMmZhYzhlY2U5MjA5ZGJlZTM2ODBkOWYxMTYxZjY3MWE2Y2NjMDNlZDllNmMyYmZjOTA5MDc%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=mMj6xnnoWyPxFGrn5U13ZrNmsC6XHuq6dWsNvu4NVdVMtge1EMIqwKkXkaHrOw6xyp78klwr%7EGUQIPKeFB3HDmlJai--11Pp1MZW2HatU4y8AvmKWfNc2rrXCA39ish-T-ySUQkbVDgWNloLoJHp1pDleS3aNypSEdM0dwLzItFCYqw9pa4eFfRgYncQ6RuYUaVp5l44%7E0axzrcixgae7VYO%7E2iPbGRtjV7aBbjzqqRT20qLyhLqsgtS97Nm72PbEYruF4FurG8IOGsDIQ2tSKWYeUPe7Y7CmJH%7Es8e2X3h1kRJKhAfqRUw7hMjRgZqNm9lE5WbBzUHaXb-zuSGSSg__&Key-Pair-Id=KVTP0A1DKRTAX: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a62105a76a4e6b9d5756eabf60d3bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00005-of-00017.bin:  90%|######### | 1.57G/1.75G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e077cec34a4547408432eb3dc125739c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00006-of-00017.bin:   0%|          | 0.00/1.75G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adae213ee0864fccb5ecdcddfe806210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00007-of-00017.bin:   0%|          | 0.00/1.75G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea845faf413b473e9b00c6f25a1b3ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00008-of-00017.bin:   0%|          | 0.00/1.75G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "992b62e8510b4438bf5d92ad18a12313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00009-of-00017.bin:   0%|          | 0.00/1.75G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d0dc8c8f72437bb5e9e3a57bc31ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00010-of-00017.bin:   0%|          | 0.00/1.75G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c21d243ca91402686bb3692e49b72e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00011-of-00017.bin:   0%|          | 0.00/1.75G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057ee1d11f6a4b87a40e6c8305644cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00012-of-00017.bin:   0%|          | 0.00/1.75G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc409c00a97c4adeafc815a393fa0628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00013-of-00017.bin:   0%|          | 0.00/1.75G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53842eadb00406184c65ed3dcf9ac15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00014-of-00017.bin:   0%|          | 0.00/1.75G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0d2386e9194674a4b6644aedb492da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00015-of-00017.bin:   0%|          | 0.00/1.75G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf623631ee934d4aaac098ec3f81a93a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00016-of-00017.bin:   0%|          | 0.00/1.75G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac51cfea2d343e1bfa8eefb70728093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00017-of-00017.bin:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea702cceb6ca439989141689cb09612c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cheng-ubuntu/anaconda3/envs/6758hmk4/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68db87a168541169f4e5a1b3b066766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94787e04f72e418eaa5e2d83a18e2330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/264 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d609f91ff5f43ffaeddf2b13490b3f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9fb37f8f0964fe793dea180752902ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "2024-03-05 21:02:39.948861: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 21:02:39.981729: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-05 21:02:40.164903: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-05 21:02:40.164988: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-05 21:02:40.166198: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-05 21:02:40.258003: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-05 21:02:40.850562: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In a shocking finding, scientist discovered a herd of dragons living in a remote, previously unexplored valley, in Tibet. Even more surprising to the researchers was the fact that the dragons spoke perfect Chinese.\n",
      "\n",
      "The dragons were able to communicate with the scientists in perfect Mandarin Chinese, and they were able to communicate with each other in the same language. The dragons were able to communicate with the scientists\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"RWKV/rwkv-raven-7b\", torch_dtype=torch.float16).to(0)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"RWKV/rwkv-raven-7b\")\n",
    "\n",
    "prompt = \"\\nIn a shocking finding, scientist discovered a herd of dragons living in a remote, previously unexplored valley, in Tibet. Even more surprising to the researchers was the fact that the dragons spoke perfect Chinese.\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(0)\n",
    "output = model.generate(inputs[\"input_ids\"], max_new_tokens=40)\n",
    "print(tokenizer.decode(output[0].tolist(), skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5d48f2-4c95-484b-97f7-ee6303d0315d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de532e23-a78a-4e16-961a-64741c680d29",
   "metadata": {},
   "source": [
    "# GPT-J\n",
    "## causal model 6B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea3d8b2-c47a-40c0-9f58-0311d185a675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9529064397a4ba08f6207bb0472a14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/619 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a559377939214545b33357ba12297092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24082baa7275409e992120fcabf2f5bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85ebab1da9e45e9ae176d9f01b841c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.37M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e022b3cb6e43a3bd4b9f43796970c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/4.04k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c17b4e8d3f4948907299b6be0fdf35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/357 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f7fc0293194d759a4e9f3911ae8531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/930 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35aceb99b64849528283494c60817832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/24.2G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.huggingface.co/EleutherAI/gpt-j-6B/0e183edc2025ecfdba4429ba43c960224103b3c3dc26616503cdc2158a3d6c93?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1709952254&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTk1MjI1NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9FbGV1dGhlckFJL2dwdC1qLTZCLzBlMTgzZWRjMjAyNWVjZmRiYTQ0MjliYTQzYzk2MDIyNDEwM2IzYzNkYzI2NjE2NTAzY2RjMjE1OGEzZDZjOTM%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=aFB8XN4%7EqL27sXq9MfJEbfPotuW5yX4W2WBQQGqHUGuRVO6fxRu-RtXu1O61KYA3tuw6SLgvnJyI1xWmnT-BwlVM-3NIxPqfSnojJJUTc32AYDHBgCK2zhuZhi61TbbtO%7E3RgEcdLL6ZCQwJ2Bz7O403R7rUSgi-0iRozJN3XrJx9fKT2ouhhjzcsHc1t%7Et88wY6ILM-VgUqCPH-BpxsdOoWB-4d7keguC2VlshpLoi2Cxqa5UH9t1qV3YSiZm6USMz5vbyd419ElDG-8YYttADRsvIukXIILdba5ZkjWXIklO5Ra541cwjYf9oAtMeuJsZ9O9FVmw2iH%7EJluyt8-A__&Key-Pair-Id=KVTP0A1DKRTAX: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f3c9366a90049f2a532c381adcd792a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   4%|3         | 881M/24.2G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, GPTJForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "model = GPTJForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2a9fca-2406-4def-9170-2a07f6a88027",
   "metadata": {},
   "source": [
    "## sequence classification multi-class\n",
    "use TFGPT-J because only they have the 6B model scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9babb123-32d8-4e0f-93e7-641bb99df631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFGPTJForSequenceClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "model = TFGPTJForSequenceClassification.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"tf\")\n",
    "\n",
    "logits = model(**inputs).logits\n",
    "\n",
    "predicted_class_id = int(tf.math.argmax(logits, axis=-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f218150c-e04c-42b3-8600-a6b3a9649dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To train a model on `num_labels` classes, you can pass `num_labels=num_labels` to `.from_pretrained(...)`\n",
    "# num_labels = len(model.config.id2label)\n",
    "# model = TFGPTJForSequenceClassification.from_pretrained(\"EleutherAI/gpt-j-6B\", num_labels=num_labels)\n",
    "\n",
    "# labels = tf.constant(1)\n",
    "# loss = model(**inputs, labels=labels).loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da8c564-1969-4dcd-9697-c03fd8428273",
   "metadata": {},
   "source": [
    "## question answering\n",
    "model scale: 6B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dde126-c50e-46ca-8f36-b44861c65cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFGPTJForQuestionAnswering\n",
    "import tensorflow as tf\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "model = TFGPTJForQuestionAnswering.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "\n",
    "question, text = \"Who was Jim Henson?\", \"Jim Henson was a nice puppet\"\n",
    "\n",
    "inputs = tokenizer(question, text, return_tensors=\"tf\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "answer_start_index = int(tf.math.argmax(outputs.start_logits, axis=-1)[0])\n",
    "answer_end_index = int(tf.math.argmax(outputs.end_logits, axis=-1)[0])\n",
    "\n",
    "predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71cd571-f878-4cb0-a15d-a708204f488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target is \"nice puppet\"\n",
    "target_start_index = tf.constant([14])\n",
    "target_end_index = tf.constant([15])\n",
    "\n",
    "outputs = model(**inputs, start_positions=target_start_index, end_positions=target_end_index)\n",
    "loss = tf.math.reduce_mean(outputs.loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnn_trans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
